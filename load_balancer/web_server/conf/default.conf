# LOAD BALANCING
# When handling a high volume of requests, a single server can become overwhelmed.
# To distribute the workload efficiently, we deploy multiple instances of our web application.
# NGINX acts as a load balancer, intelligently routing incoming requests to different instances,
# ensuring better performance and reliability.

# Options to redirect the requests to our backend.
upstream backend_api {
    # IMP: Prioritize sending requests to the least loaded instance
    # least_conn;
    # Ensures requests from the same IP go to the same backend instance
    # ip_hash;
    server test-api-1:8001;
    server test-api-2:8002;
    server test-api-3:8003;
}

server {
    # Instead of 80 (http).
    listen 443 ssl;
    # In the professional setting here's your domain.
    server_name localhost;
    # SSL certificate path.
    ssl_certificate /etc/nginx/certs/fullchain.pem;
    # SSL key for certificate path.
    ssl_certificate_key /etc/nginx/certs/privkey.pem;

    location / {
        # If you have your frontend managed outside nginx, fort
        # example buily in VITE + React:
        # proxy_pass [protocol]://[address]:[port];
        root /usr/share/nginx/html/;
        # proxy_set_header is used to set header pairs:
        # proxy_set_header [HEADER_NAME] [HEADER_VALUE];
        proxy_set_header Hot $host;
        proxy_set_header X-Real-Ip $remote_addr;
    }

    location /api/ {
        # proxy_pass is used to redirect to specified address.
        # backend_api is the address set from our address. 
        proxy_pass http://backend_api/;
        # Useful headers for logging.
        proxy_set_header Hot $host;
        proxy_set_header X-Real-Ip $remote_addr;
    }
}

# Setting other server directive listening to port 80 redirecting
# http addresses to our secure server.
server {
    listen 80;
    server_name localhost;
    return 301 https://$host$request_uri;
}